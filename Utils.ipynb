{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dev_path = os.path.join(cwd, '/VSD_2014_December_official_release/Hollywood-dev/')\n",
    "h_test_path = os.path.join(cwd,'/VSD_2014_December_official_release/Hollywood-test/')\n",
    "h_generalized_path = os.path.join(cwd,'/VSD_2014_December_official_release/YouTube-gen/')\n",
    "save_path = os.path.join(cwd,'/VSD_2014_December_official_release/data_arrays/')\n",
    "\n",
    "visual_features = ['CM', 'CNH', 'HOG', 'LBP']\n",
    "auditory_features = ['AE', 'BER', 'BW', 'MFCC', 'RMS', 'SC', 'SF', 'ZCR']\n",
    "# the only concept with interesting labels is blood : {'high', 'low', 'medium', 'unnoticeable'}\n",
    "visual_concepts = ['blood', 'carchase', 'coldarms', 'fights', 'fire', 'firearms', 'gore'] \n",
    "auditory_concepts = ['explosions', 'gunshots', 'screams'] # also contain 'nothing' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_annotations(dev_or_test_or_generalized, path = save_path):  \n",
    "    f = open(save_path + dev_or_test_or_generalized + r'/annotations/all_annotations.p', 'rb')\n",
    "    return pickle.load(f)\n",
    "\n",
    "def get_annotations(dev_or_test_or_generalized, audio_or_visual, path = save_path):\n",
    "    f = open(save_path + dev_or_test_or_generalized + r'/annotations/' +  'Y_' + audio_or_visual + '_dictionary.p', 'rb')\n",
    "    return pickle.load(f)   \n",
    "\n",
    "def get_annotation(dev_or_test_or_generalized, audio_or_visual, annotation, path = save_path):\n",
    "    f = open(save_path + dev_or_test_or_generalized + r'/annotations/' +  'Y_' + audio_or_visual + '_dictionary.p', 'rb')\n",
    "    d = pickle.load(f)\n",
    "    return np.array(d[annotation])\n",
    "\n",
    "def get_data(dev_or_test_or_generalized, save_path = save_path, prefix = '', extension = ''):\n",
    "    f = open(save_path + dev_or_test_or_generalized + r'/' + prefix + 'data' + extension + '.p', 'rb')\n",
    "    return pickle.load(f)   \n",
    "    \n",
    "def get_feature(dev_or_test_or_generalized, feature_name, path = save_path):\n",
    "    if feature_name in visual_features:\n",
    "        f = open(save_path + dev_or_test_or_generalized + r'/visual_features/' + feature_name + '.p', 'rb')\n",
    "        return pickle.load(f)\n",
    "    elif feature_name in auditory_features:\n",
    "        f = open(save_path + dev_or_test_or_generalized + r'/audio_features/' + feature_name + '.p', 'rb')\n",
    "        return pickle.load(f)    \n",
    "    \n",
    "def get_intervals(dev_or_test_or_generalized, path = save_path):\n",
    "    f = open(save_path + dev_or_test_or_generalized + r'/annotations/' +  'intervals_dictionary.p', 'rb')\n",
    "    return pickle.load(f)    \n",
    "\n",
    "def save_all_annotations(dev_or_test_or_generalized, save_path = save_path): \n",
    "    all_annotations = []\n",
    "    annotations_visual = get_annotations(dev_or_test_or_generalized, 'visual')\n",
    "    for concept in annotations_visual:\n",
    "        all_annotations.append(annotations_visual[concept])\n",
    "    annotations_audio = get_annotations(dev_or_test_or_generalized, 'audio')\n",
    "    for concept in annotations_audio:\n",
    "        all_annotations.append(annotations_audio[concept])\n",
    "    all_annotations = list(zip(*all_annotations))\n",
    "    f = open(save_path + dev_or_test_or_generalized + r'/annotations/all_annotations.p', 'wb')\n",
    "    pickle.dump(all_annotations, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()   \n",
    "    \n",
    "def save_annotations(path, save_path):\n",
    "    os.chdir(path)\n",
    "    Y_visual = {}\n",
    "    Y_audio = {}\n",
    "    intervals = {}\n",
    "    for vis_con in visual_concepts + ['violence']:\n",
    "        Y_visual[vis_con] = []\n",
    "        intervals[vis_con] = []\n",
    "    for audio_con in auditory_concepts: # 25 frames/second\n",
    "        Y_audio[audio_con] = []\n",
    "        intervals[audio_con] = []\n",
    "    l = 0\n",
    "    i = 0\n",
    "        \n",
    "    for file in os.listdir(path + r'features'):\n",
    "        if 'visual' in file:\n",
    "            movie_name = file[0: file.rfind('_')]  \n",
    "            f1 = h5py.File(path + r'features/' + movie_name + '_visual.mat')\n",
    "            f2 = h5py.File(path + r'features/' + movie_name + '_auditory.mat')\n",
    "            l = min([f1['CM'].shape[0], f2['ZCR'].shape[0]]) # cut to have same indexing  \n",
    "            #print('From ' + str(i) + ' to ' + str(i + l - 1) + ' are features of ' + movie_name)\n",
    "            f1.close()\n",
    "            f2.close()\n",
    "            \n",
    "            for vis_con in visual_concepts + ['violence']:\n",
    "                if 'generalized' in save_path and vis_con == 'violence':\n",
    "                    annotation_file_path = path + r'annotations/' + movie_name + '.txt'\n",
    "                else:\n",
    "                    annotation_file_path = path + r'annotations/' + movie_name + '_' + vis_con + '.txt'\n",
    "                if os.path.isfile(annotation_file_path):\n",
    "                    annotation_file = open(annotation_file_path, 'r')\n",
    "                    if vis_con == 'blood' :\n",
    "                        Y_visual[vis_con].extend(['0'] * l)\n",
    "                        for line in annotation_file.readlines():\n",
    "                            contents = line.split(' ') \n",
    "                            if len(contents) >= 3:\n",
    "                                a, b, c = line.split(' ')[0:3]\n",
    "                                c = c.replace('\\n', '')\n",
    "                                a = int(a)\n",
    "                                b = min([int(b), l - 1]) # frame intervals are closed, indexing starts from 0\n",
    "                                for j in range(a, b + 1):\n",
    "                                    Y_visual[vis_con][i + j] = c\n",
    "                                intervals[vis_con].append((i + a, i + b, c))\n",
    "                    else:        \n",
    "                        Y_visual[vis_con].extend([0] * l)\n",
    "                        for line in annotation_file.readlines():\n",
    "                            contents = line.split(' ') \n",
    "                            if len(contents) >= 2:\n",
    "                                a, b = line.split(' ')[0:2]\n",
    "                                a = int(a)\n",
    "                                b = min([int(b), l - 1])\n",
    "                                for j in range(a, b + 1):\n",
    "                                    Y_visual[vis_con][i + j] = 1\n",
    "                                intervals[vis_con].append((i + a, i + b))\n",
    "                    annotation_file.close()\n",
    "                else:\n",
    "                    Y_visual[vis_con].extend([0] * l)\n",
    "                    \n",
    "            for audio_con in auditory_concepts:\n",
    "                annotation_file_path = path + r'annotations/' + movie_name + '_' + audio_con + '.txt'\n",
    "                if os.path.isfile(annotation_file_path):\n",
    "                    annotation_file = open(annotation_file_path, 'r')\n",
    "                    Y_audio[audio_con].extend([0] * l)\n",
    "                    for line in annotation_file.readlines():\n",
    "                        contents = line.split(' ')\n",
    "                        if len(contents) >= 2:\n",
    "                            a, b = line.split(' ')[0:2]\n",
    "                            a = math.floor(float(a) * 25) # 25 frames per second\n",
    "                            b = min([math.ceil(float(b) * 25), l - 1])\n",
    "                            if not (len(contents) >= 3 and 'nothing' in contents[2]):\n",
    "                                for j in range(a, b + 1):\n",
    "                                    Y_audio[audio_con][i + j] = 1\n",
    "                                intervals[audio_con].append((i + a, i + b))\n",
    "                    annotation_file.close()                \n",
    "                else:\n",
    "                    Y_audio[audio_con].extend([0] * l)\n",
    "            i += l\n",
    "            \n",
    "    f = open(save_path + r'annotations/' + 'Y_visual_dictionary.p', 'wb')\n",
    "    pickle.dump(Y_visual, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "    f = open(save_path + r'annotations/' + 'Y_audio_dictionary.p', 'wb')\n",
    "    pickle.dump(Y_audio, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "    f = open(save_path + r'annotations/' + 'intervals_dictionary.p', 'wb')\n",
    "    pickle.dump(intervals, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "    print(intervals)\n",
    "    \n",
    "def save_data(dev_or_test_or_generalized, save_path = save_path):\n",
    "    data = []\n",
    "    features = []\n",
    "    for feature_name in visual_features + auditory_features:\n",
    "        features.append(get_feature(dev_or_test_or_generalized, feature_name)) \n",
    "    data = np.concatenate(features, axis = 1)\n",
    "    f = open(save_path + dev_or_test_or_generalized + r'/data.p', 'wb')\n",
    "    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()   \n",
    "    \n",
    "def save_data_compressed(dev_or_test_or_generalized, window, save_path = save_path, prefix = '', extension = ''):\n",
    "    data = get_data(dev_or_test_or_generalized, save_path, prefix, extension)\n",
    "    data_compressed = []\n",
    "    for i in range(0, data.shape[0] - window, window):\n",
    "        data_compressed.append(np.concatenate(data[i: i + window]))\n",
    "    i += window\n",
    "    if i < data.shape[0]:\n",
    "        if window - data.shape[0] + i == 0:\n",
    "            data_compressed.append(np.concatenate(data[i: data.shape[0]]))\n",
    "        else:\n",
    "            data_compressed.append(np.concatenate(np.vstack((data[i: data.shape[0]], [data[-1]] * \n",
    "                                                             (window - data.shape[0] + i)))))\n",
    "    data_compressed = np.array(data_compressed)\n",
    "    f = open(save_path + dev_or_test_or_generalized + r'/' + prefix + 'data' + extension + '_compressed_' + \n",
    "             str(window) + '.p', 'wb')\n",
    "    pickle.dump(data_compressed, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()             \n",
    "    \n",
    "def save_data_pca(dev_or_test_or_generalized, n_components, save_path = save_path):\n",
    "    data = get_data(dev_or_test_or_generalized)\n",
    "    pca = PCA(n_components = n_components)    \n",
    "    f = open(save_path + dev_or_test_or_generalized+ r'/data_pca_' + str(n_components) + '.p', 'wb')\n",
    "    pickle.dump(pca.fit_transform(data), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()    \n",
    "    \n",
    "def save_data_timestamped(dev_or_test_or_generalized, timestamp, save_path = save_path): \n",
    "    data = get_data(dev_or_test_or_generalized, save_path = save_path)\n",
    "    l = data.shape[0]\n",
    "    timestamped_data = [] # timestamps = [timestamp] * (l // timestamp) + [l - timestamp * (l // timestamp)]\n",
    "    i = 0\n",
    "    while i < l:\n",
    "        timestamped_vector = []\n",
    "        for i in range(i, min((i + timestamp, l))):\n",
    "            timestamped_vector.append(data[i]) \n",
    "        timestamped_data.append(timestamped_vector)\n",
    "        i += 1\n",
    "    timestamped_data = np.array(timestamped_data)\n",
    "    f = open(save_path + dev_or_test_or_generalized+ r'/data_timestamped_' + str(timestamp) + '.p', 'wb')\n",
    "    pickle.dump(timestamped_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()  \n",
    "    \n",
    "def save_feature(path, save_path, feature_name):\n",
    "    os.chdir(path)\n",
    "    feature = []\n",
    "    i = 0\n",
    "    l = 0\n",
    "    \n",
    "    for file in os.listdir(path + r'features'):\n",
    "        if 'visual' in file:\n",
    "            movie_name = file[0: file.rfind('_')]           \n",
    "            f1 = h5py.File(path + r'features/' + movie_name + '_visual.mat')\n",
    "            f2 = h5py.File(path + r'features/' + movie_name + '_auditory.mat')\n",
    "            l = min([f1['CM'].shape[0], f2['ZCR'].shape[0]]) # cut to have same indexing \n",
    "            \n",
    "            if feature_name in visual_features:\n",
    "                for j in range(l):\n",
    "                    feature.append(np.nan_to_num(f1[feature_name][j]))\n",
    "            elif feature_name in auditory_features:\n",
    "                for j in range(l):\n",
    "                    feature.append(np.nan_to_num(f2[feature_name][j]))\n",
    "            f1.close()\n",
    "            f2.close()\n",
    "    \n",
    "    if feature_name in visual_features:    \n",
    "        f = open(save_path + r'visual_features/' + feature_name + '.p', 'wb')\n",
    "        pickle.dump(feature, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "    elif feature_name in auditory_features:    \n",
    "        f = open(save_path + r'audio_features/' + feature_name + '.p', 'wb')\n",
    "        pickle.dump(feature, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(path = h_dev_path + r'annotations/'):\n",
    "    violence_intervals = {}\n",
    "    total_movies_violence_frames = {}\n",
    "    for file in os.listdir(path):\n",
    "        if 'violence' in file:\n",
    "            movie = file[0: file.rfind('_')]\n",
    "            violence_intervals[movie] = get_intervals_no_labels(path + file, 'violence')\n",
    "            total_movies_violence_frames[movie] = get_total_frames(violence_intervals[movie])\n",
    "    print_concepts_stats(path, violence_intervals, total_movies_violence_frames)\n",
    "    \n",
    "def get_intervals_no_labels(file_path, concept):\n",
    "    f = open(file_path, 'r')\n",
    "    intervals = []\n",
    "    is_audio = concept in auditory_concepts\n",
    "    for line in f.readlines():\n",
    "        contents = line.split(' ')\n",
    "        if len(contents) >= 2:\n",
    "            a, b = contents[0: 2]\n",
    "            if is_audio: # need to convert to frame intervals\n",
    "                a = math.floor(float(a) * 25) \n",
    "                b = math.ceil(float(b) * 25)\n",
    "                if not (len(contents) >= 3 and 'nothing' in contents[2]): \n",
    "                    intervals.append((a, b))\n",
    "            else:\n",
    "                intervals.append((int(a), int(b)))\n",
    "    f.close()\n",
    "    return intervals \n",
    "\n",
    "def get_intervals_with_labels(file_path, concept):\n",
    "    f = open(file_path, 'r')\n",
    "    intervals = []\n",
    "    is_audio = concept in auditory_concepts\n",
    "    for line in f.readlines():\n",
    "        contents = line.split(' ') \n",
    "        if len(contents) >= 3:\n",
    "            a, b, c = contents[0: 3]\n",
    "            if is_audio:\n",
    "                a = math.floor(float(a) * 25) \n",
    "                b = math.ceil(float(b) * 25)\n",
    "                intervals.append((a, b, c.replace('\\n', '')))                \n",
    "            else:\n",
    "                intervals.append((int(a), int(b), c.replace('\\n', '')))\n",
    "    f.close()\n",
    "    return intervals\n",
    "    \n",
    "def print_concepts_stats(path, violence_intervals, total_movies_violence_frames):\n",
    "    concept_movies = {}\n",
    "    for concept in visual_concepts + auditory_concepts:\n",
    "        concept_movies[concept] = []        \n",
    "    for file in os.listdir(path):\n",
    "        for concept in visual_concepts + auditory_concepts:\n",
    "            if concept in file:\n",
    "                concept_movies[concept].append(file[0 : file.rfind('_')])\n",
    "            \n",
    "    for concept in visual_concepts[1 :] + auditory_concepts: # blood special case, has interesting labels\n",
    "        print(concept)\n",
    "        total_violent_frames = 0\n",
    "        concept_frames = 0\n",
    "        concept_violence_frames = 0\n",
    "        for movie in concept_movies[concept]:\n",
    "            intervals = get_intervals_no_labels(path + movie + '_' + concept + '.txt', concept)\n",
    "            total_frames = get_total_frames(intervals)\n",
    "            overlap = get_overlap_no_labels(intervals, violence_intervals[movie])\n",
    "            total_violent_frames += total_movies_violence_frames[movie]\n",
    "            concept_frames += total_frames\n",
    "            concept_violence_frames += overlap\n",
    "            print('In ' + movie + ' there are ' + str(total_movies_violence_frames[movie]) + ' frames with violence')\n",
    "            print('In ' + movie + ' there are ' + str(total_frames) + ' frames with ' + concept)\n",
    "            print('In ' + movie + ' ' + str(overlap) + ' ' + concept + ' frames are also frames with violence')\n",
    "            if total_frames > 0:\n",
    "                print('In ' + movie + ' ' + str(overlap / total_frames * 100) + '% of frames with ' + concept + \n",
    "                      ' are frames with violence')\n",
    "            if total_movies_violence_frames[movie] > 0:\n",
    "                print('In ' + movie + ' ' + str(overlap / total_movies_violence_frames[movie] * 100) + \n",
    "                      '% of frames with violence contain ' + concept)            \n",
    "        print()\n",
    "        print('In total, out of ' + str(total_violent_frames) + ' frames with violence, ' + \n",
    "              str(concept_violence_frames) + ' contain ' + concept)\n",
    "        if total_violent_frames > 0:\n",
    "            print('That is ' + str(concept_violence_frames / total_violent_frames * 100) +'%')\n",
    "        print('In total, out of ' + str(concept_frames) + ' frames with ' + concept + ' ' + \n",
    "              str(concept_violence_frames) + ' contain violence')\n",
    "        if concept_frames > 0:\n",
    "            print('That is ' + str(concept_violence_frames / concept_frames * 100) +'%')\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "    print('blood')\n",
    "    total_violent_frames = 0\n",
    "    blood_frames = 0\n",
    "    blood_labelled_frames = {}\n",
    "    blood_violence_frames = 0\n",
    "    blood_labelled_violence_frames = {}\n",
    "    for movie in concept_movies['blood']:\n",
    "        total_frames = 0\n",
    "        movie_overlap = 0\n",
    "        total_violent_frames += total_movies_violence_frames[movie]\n",
    "        intervals_with_labels = get_intervals_with_labels(path + movie + '_blood.txt', 'blood')\n",
    "        labelled_intervals = get_labelled_intervals(intervals_with_labels)\n",
    "        for label in labelled_intervals:\n",
    "            overlap = get_overlap_no_labels(labelled_intervals[label], violence_intervals[movie])\n",
    "            movie_overlap += overlap\n",
    "            blood_violence_frames += overlap\n",
    "            labelled_frames = get_total_frames(labelled_intervals[label])\n",
    "            total_frames += labelled_frames\n",
    "            blood_frames += labelled_frames\n",
    "            if label not in blood_labelled_frames:\n",
    "                blood_labelled_frames[label] = labelled_frames\n",
    "            else:\n",
    "                blood_labelled_frames[label] += labelled_frames\n",
    "            if label not in blood_labelled_violence_frames:\n",
    "                blood_labelled_violence_frames[label] = overlap\n",
    "            else:\n",
    "                blood_labelled_violence_frames[label] += overlap\n",
    "            print('In ' + movie + ' there are ' + str(total_movies_violence_frames[movie]) + ' frames with violence')\n",
    "            print('In ' + movie + ' there are ' + str(labelled_frames) + ' frames with blood labelled ' + label)\n",
    "            print('In ' + movie + ' ' + str(overlap) + ' frames with blood labelled ' + label + \n",
    "                  ' frames are also frames with violence')\n",
    "            if labelled_frames > 0:\n",
    "                print('In ' + movie + ' ' + str(overlap / labelled_frames * 100) + \n",
    "                      '% of frames with blood labellled ' + label + ' are frames with violence')\n",
    "            if total_movies_violence_frames[movie] > 0:\n",
    "                print('In ' + movie + ' ' + str(overlap / total_movies_violence_frames[movie] * 100) + \n",
    "                      '% of frames with violence contain blood labelled ' + label)\n",
    "        print()\n",
    "        print('In ' + movie + ' there are ' + str(total_frames) + ' frames with blood')\n",
    "        print('In ' + movie + ' ' + str(movie_overlap) +  ' blood frames are also frames with violence')\n",
    "        if total_frames > 0:\n",
    "            print('That is ' + str(movie_overlap / total_frames * 100) +'%')\n",
    "        if total_movies_violence_frames[movie] > 0:\n",
    "            print('In ' + movie + ' ' + str(movie_overlap / total_movies_violence_frames[movie] * 100) + \n",
    "                  '% of frames with violence contain ' + 'blood')            \n",
    "        print()\n",
    "    print()\n",
    "    for label in blood_labelled_frames:\n",
    "        print('In total, out of ' + str(total_violent_frames) + ' frames with violence, ' + \n",
    "              str(blood_labelled_frames[label]) + ' contain blood labelled ' + label)\n",
    "        if total_violent_frames > 0:\n",
    "            print('That is ' + str(blood_labelled_frames[label] / total_violent_frames * 100) + '%')\n",
    "        print('In total, out of ' + str(blood_labelled_frames[label]) + ' frames with ' + label + ' blood, ' + \n",
    "              str(blood_labelled_violence_frames[label]) + ' are also frames wih violence')\n",
    "        if blood_labelled_frames[label] > 0:\n",
    "            print('That is ' + str(blood_labelled_violence_frames[label] / blood_labelled_frames[label] * 100) + '%')\n",
    "    print()\n",
    "    print('In total, out of ' + str(total_violent_frames) + ' frames with violence, ' + \n",
    "          str(blood_violence_frames) + ' contain blood')\n",
    "    if total_violent_frames > 0:\n",
    "        print('That is ' + str(blood_violence_frames / total_violent_frames * 100) +'%')\n",
    "    print('In total, out of ' + str(blood_frames) + ' frames with ' + 'blood' + ' ' + \n",
    "          str(blood_violence_frames) + ' contain violence')\n",
    "    if blood_frames > 0:\n",
    "        print('That is ' + str(blood_violence_frames / blood_frames * 100) +'%')\n",
    "    print()\n",
    "    print()\n",
    "            \n",
    "            \n",
    "def get_labelled_intervals(intervals_with_labels):\n",
    "    labelled_intervals = {}\n",
    "    labels = get_labels(intervals_with_labels)\n",
    "    for label in labels:\n",
    "        labelled_intervals[label] = []\n",
    "    for interval_with_label in intervals_with_labels:\n",
    "        labelled_intervals[interval_with_label[2]].append(interval_with_label[0: 2])\n",
    "    return labelled_intervals     \n",
    "        \n",
    "def get_labels(intervals_with_labels):\n",
    "    labels = set()\n",
    "    for i in range(len(intervals_with_labels)):\n",
    "        labels.add(intervals_with_labels[i][2])\n",
    "    return labels\n",
    "            \n",
    "def get_overlap_no_labels(intervals1, intervals2): \n",
    "    i = 0\n",
    "    j = 0\n",
    "    frames = 0 \n",
    "    while i < len(intervals1) and j < len(intervals2):\n",
    "        a, b = intervals1[i]\n",
    "        x, y = intervals2[j]\n",
    "        if a >= x and b <= y:\n",
    "            frames += b - a + 1\n",
    "            i += 1\n",
    "        elif x >= a and y <= b:\n",
    "            frames += y - x + 1\n",
    "            j += 1\n",
    "        elif a <= x and x <= b and b <= y:\n",
    "            frames += b - x + 1\n",
    "            i += 1\n",
    "        elif a >= x and a <= y and y <= b:\n",
    "            frames += y - a + 1\n",
    "            j += 1\n",
    "        elif b <= x:\n",
    "            i += 1\n",
    "        elif a >= y:\n",
    "            j += 1\n",
    "    return frames\n",
    "\n",
    "def get_total_frames(intervals):\n",
    "    frames = 0\n",
    "    for i in range(len(intervals)):\n",
    "        frames += intervals[i][1] - intervals[i][0] + 1\n",
    "    return frames                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map2014(predicted_intervals, intervals):\n",
    "    score = 0\n",
    "    hits = 0\n",
    "    m = len(predicted_intervals)\n",
    "    found_intervals = set()\n",
    "    j = 0\n",
    "    for i in range(m):\n",
    "        flag, hit_interval = is_hit(predicted_intervals[i], intervals) \n",
    "        if flag: # non-new hits do not count as false positives\n",
    "            if hit_interval not in found_intervals:\n",
    "                hits += 1\n",
    "                found_intervals.add(hit_interval)\n",
    "                j += 1\n",
    "                score += hits / j\n",
    "        else:\n",
    "            j += 1\n",
    "    return score / len(intervals)\n",
    "\n",
    "def map_classic(predicted_intervals, intervals): # multiple hits on the same interval counted\n",
    "    score = 0\n",
    "    hits = 0\n",
    "    m = len(predicted_intervals)\n",
    "    j = 0\n",
    "    for i in range(m):\n",
    "        flag, hit_interval = is_hit(predicted_intervals[i], intervals) \n",
    "        if flag: \n",
    "            hits += 1\n",
    "            j += 1\n",
    "            score += hits / j\n",
    "        else:\n",
    "            j += 1\n",
    "    return score / len(intervals)\n",
    "\n",
    "def is_hit(interval, intervals):\n",
    "    flag = False\n",
    "    hit_interval = (0, 0)\n",
    "    for i in range(len(intervals)):\n",
    "        overlap = get_overlap(interval, intervals[i])\n",
    "        if overlap / (intervals[i][1] - intervals[i][0]) > 0.5:\n",
    "            flag = True\n",
    "            hit_interval = intervals[i]\n",
    "    return flag, hit_interval\n",
    "\n",
    "def get_overlap(interval1, interval2):\n",
    "    a, b = interval1\n",
    "    x, y = interval2\n",
    "    if a >= x and b <= y:\n",
    "        return b - a + 1\n",
    "    elif x >= a and y <= b:\n",
    "        return y - x + 1\n",
    "    elif a <= x and x <= b and b <= y:\n",
    "        return b - x + 1\n",
    "    elif a >= x and a <= y and y <= b:\n",
    "        return y - a + 1\n",
    "    return 0\n",
    "\n",
    "def print_conf_matrix(predicted_frames, frames):\n",
    "    tn, fp, fn, tp = 0, 0, 0, 0\n",
    "    l = len(frames)\n",
    "    for i in range(l):\n",
    "        if predicted_frames[i] == 0 and frames[i] == 0:\n",
    "            tn+= 1\n",
    "        elif predicted_frames[i] == 1 and frames[i] == 0:\n",
    "            fp+= 1\n",
    "        elif predicted_frames[i] == 0 and frames[i] == 1:\n",
    "            fn+= 1\n",
    "        elif predicted_frames[i] == 1 and frames[i] == 1:\n",
    "            tp+= 1\n",
    "    precision, recall = 0, 0            \n",
    "    if tp + fp > 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    if tp + fn > 0:\n",
    "        recall = tp / (tp + fn)\n",
    "    print('Precision: '+str(precision))\n",
    "    print('Recall: '+str(recall))\n",
    "    print('Accuracy: '+str((tp + tn) / (tp + fp + tn + fn)))\n",
    "    print('     T       F')\n",
    "    print('P    '+str(tp)+' '*(8-len(str(tp)))+str(fp))\n",
    "    print('N    '+str(tn)+' '*(8-len(str(tn)))+str(fn))\n",
    "\n",
    "def k_fold_gap_validation(get_model, data, annotations, k, lower, upper, step):\n",
    "    N = len(data)\n",
    "    frames_predictions = []\n",
    "    scores = []\n",
    "    for i in range(k):\n",
    "        model = get_model()\n",
    "        model.fit(np.concatenate((data[:i * N // k], data[(i + 1) * N // k:])), np.concatenate((\n",
    "            annotations[:i * N // k], annotations[(i + 1) * N // k:])))\n",
    "        frames_predictions.append(model.predict(data[i * N // k: (i + 1) * N // k]))   \n",
    "    for gap in range(lower, upper, step):\n",
    "        score = 0\n",
    "        for i in range(k):\n",
    "            frames_predicted = frames_predictions[i]\n",
    "            frames_smoothed = smooth(frames_predicted)\n",
    "            frames_merged = merge(frames_smoothed, gap) \n",
    "            score += map2014(frames_to_intervals(frames_merged), frames_to_intervals(\n",
    "                annotations[i * N // k: (i + 1) * N // k]))\n",
    "        scores.append(score / k)\n",
    "    best = max(scores)\n",
    "    return scores.index(best) * step + lower, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(save_path, model, model_name):\n",
    "    os.chdir(save_path + r'/models')\n",
    "    model.save(model_name + '.h5')\n",
    "    \n",
    "def load_model(save_path, model_name):\n",
    "    os.chdir(save_path + r'/models')\n",
    "    return models.load_model(model_name + '.h5')\n",
    "\n",
    "def get_layer_output(model, layer_name, data): # use for neural networks\n",
    "    extractor = Model(inputs=model.inputs, outputs=[model.get_layer(layer_name).output])\n",
    "    res = extractor.predict(data)\n",
    "    res = np.array(res)\n",
    "    return res \n",
    "\n",
    "def multi_loss_3(y_true, y_pred):\n",
    "    loss = 0\n",
    "    weights = [1 / 3] * 3\n",
    "    bce = bce = tf.keras.losses.binary_crossentropy\n",
    "    for i in range(3):\n",
    "        s = 0\n",
    "        s += bce(y_true[:,i], y_pred[:,i])\n",
    "        loss += weights[i] * s\n",
    "    return loss \n",
    "\n",
    "def get_sequence(data, window): # use for LSTM\n",
    "    sequence = []\n",
    "    for i in range(0, data.shape[0] - window, window):\n",
    "        sequence.append(data[i: i + window])\n",
    "    i += window\n",
    "    if i < data.shape[0]:\n",
    "        if window - data.shape[0] + i == 0:\n",
    "            sequence.append(data[i: data.shape[0]])\n",
    "        else:\n",
    "            sequence.append(np.concatenate((data[i: data.shape[0]], [data[-1]] * (window - data.shape[0] + i))))\n",
    "    return np.array(sequence)   \n",
    "\n",
    "def smooth(frames, window = 25, threshold = 0.5): # 25 fps\n",
    "    smoothed_frames = []\n",
    "    frames_number = len(frames)\n",
    "    i = 0\n",
    "    while i < frames_number:\n",
    "        window_score = 0\n",
    "        j = 0\n",
    "        while i + j < frames_number and j < window:\n",
    "            window_score += frames[i]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        if window_score / j >= threshold:\n",
    "            smoothed_frames.extend([1] * j)\n",
    "        else:\n",
    "            smoothed_frames.extend([0] * j)\n",
    "    return np.array(smoothed_frames)\n",
    "\n",
    "def merge(frames, gap):\n",
    "    frames_number = len(frames)\n",
    "    new_frames = frames.copy()\n",
    "    i = 0\n",
    "    while i < frames_number:\n",
    "        if new_frames[i] == 1:\n",
    "            while i < frames_number and new_frames[i] == 1:\n",
    "                i += 1\n",
    "            j = i\n",
    "            merge_flag = False\n",
    "            while j < min([frames_number, i + gap]):\n",
    "                if new_frames[j] == 1:\n",
    "                    merge_flag = True\n",
    "                    break\n",
    "                j += 1\n",
    "            if merge_flag:\n",
    "                while i < j:\n",
    "                    new_frames[i] = 1\n",
    "                    i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return np.array(new_frames)\n",
    "\n",
    "def compress(frames, window, threshold = 0.5):\n",
    "    frames_compressed = []\n",
    "    for i in range(0, frames.shape[0] - window, window):\n",
    "        if sum(frames[i: i + window]) / window >= threshold:\n",
    "            frames_compressed.append(1)\n",
    "        else:        \n",
    "            frames_compressed.append(0)\n",
    "    i += window\n",
    "    if i < frames.shape[0]:\n",
    "        if (sum(frames[i: frames.shape[0]]) + frames[-1] * (window - frames.shape[0] + i)) / window >= threshold:\n",
    "            frames_compressed.append(1)\n",
    "        else:\n",
    "            frames_compressed.append(0)\n",
    "    return np.array(frames_compressed) \n",
    "    \n",
    "def decompress(frames, window, length = None):\n",
    "    frames_decompressed = []\n",
    "    for a in frames:\n",
    "        frames_decompressed.extend([a] * window)\n",
    "    if length != None:\n",
    "        frames_decompressed = frames_decompressed[:length]\n",
    "    return np.array(frames_decompressed)  \n",
    "    \n",
    "def frames_to_intervals(frames):\n",
    "    intervals = []\n",
    "    frames_number = len(frames)\n",
    "    i = 0\n",
    "    while i < frames_number:\n",
    "        if frames[i] == 1:\n",
    "            j = i\n",
    "            while j < frames_number and frames[j] == 1:\n",
    "                j += 1    \n",
    "            intervals.append((i, j))\n",
    "            i = j\n",
    "        else:\n",
    "            i += 1\n",
    "    return intervals\n",
    "\n",
    "def get_predictions(sigmoid_values):\n",
    "    y_pred = []\n",
    "    l = sigmoid_values.shape[0]\n",
    "    for i in range(l):\n",
    "        y_pred.append(round(sigmoid_values[i][0]))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def class_weight(frames, fp_bias = 0):\n",
    "    positives = np.sum(frames)\n",
    "    negatives = np.size(frames) - positives\n",
    "    return {0 : 1 + positives/negatives, 1: 1 + (negatives + fp_bias)/positives}\n",
    "\n",
    "def one_hot_encode(labelled_frames):\n",
    "    labels_dictionary = {}\n",
    "    label = 0\n",
    "    for l in set(labelled_frames):\n",
    "        labels_dictionary[l] = label\n",
    "        label += 1\n",
    "    res = []\n",
    "    for l in labelled_frames:\n",
    "        encoding = np.array([0] * label)\n",
    "        encoding[labels_dictionary[l]] = 1\n",
    "        res.append(encoding)  \n",
    "    return np.array(res)                   \n",
    "    \n",
    "def azip(ys):\n",
    "    res = []\n",
    "    for i in range(ys[0].shape[0]):\n",
    "        column = []\n",
    "        for j in range(len(ys)):\n",
    "                for k in range(ys[j].shape[1]):\n",
    "                    column.append(ys[j][i][k])\n",
    "        res.append(np.array(column))\n",
    "    return np.array(res)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, frames_test, gap = None): \n",
    "    frames_predicted = np.array(model.predict(data))\n",
    "    print_conf_matrix(frames_predicted, frames_test)\n",
    "    print(map_classic(frames_to_intervals(frames_predicted), frames_to_intervals(frames_test)))\n",
    "    frames_smoothed = smooth(frames_predicted)\n",
    "    print(map_classic(frames_to_intervals(frames_smoothed), frames_to_intervals(frames_test)))\n",
    "    best_score = 0\n",
    "    best_gap = 0\n",
    "    if gap != None:\n",
    "        best_gap = gap\n",
    "    else:\n",
    "        for gap in range(0, 600, 100): \n",
    "            frames_merged = merge(frames_smoothed, gap)\n",
    "            score = map_classic(frames_to_intervals(frames_merged), frames_to_intervals(frames_test))\n",
    "            print((gap, score), end = '  ')\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_gap = gap\n",
    "    print()\n",
    "    print(str(best_score) + ' ' + str(best_gap))\n",
    "    frames_merged = merge(frames_smoothed, best_gap)\n",
    "    print_conf_matrix(frames_merged, frames_test)\n",
    "    return best_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
